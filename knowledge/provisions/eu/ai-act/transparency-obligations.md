# EU AI Act — Transparency Obligations

**Law**: Regulation (EU) 2024/1689 (EU Artificial Intelligence Act)
**Articles**: Articles 50-52
**Effective**: 2 August 2025 (transparency obligations for GPAI);
2 August 2026 (transparency obligations for other AI systems)

## Overview

The EU AI Act imposes transparency obligations on certain AI systems regardless
of their risk classification. These obligations ensure that individuals are
aware when they are interacting with AI, when content has been AI-generated,
or when they are subject to AI-based categorisation or emotion recognition.

## Article 50 — Transparency Obligations for Providers and Deployers

### 50(1) — AI Systems Interacting with Natural Persons

Providers must ensure that AI systems intended to interact directly with
natural persons are designed and developed in such a way that the natural
person is informed that they are interacting with an AI system, unless this
is obvious from the circumstances and context of use.

**Applies to**: Chatbots, virtual assistants, conversational AI, AI customer
service agents, AI phone systems, and any AI system that communicates directly
with users.

**What's required**:
- Clear disclosure at the point of interaction
- Must be provided before or at the start of the interaction
- Disclosure must be clear, understandable, and timely

**Exceptions**: Not required when obvious from context (e.g., clearly
labelled AI features in a product interface where the AI nature is apparent).

### 50(2) — Emotion Recognition and Biometric Categorisation

Providers of AI systems that perform emotion recognition or biometric
categorisation must inform the natural persons exposed thereto of the
operation of the system. Deployers must also inform those exposed.

Where such systems are used in law enforcement contexts (as permitted),
appropriate transparency measures must still be taken.

### 50(3) — AI-Generated Content (Deepfakes)

Providers of AI systems that generate or manipulate image, audio, or video
content constituting a deep fake must disclose that the content has been
artificially generated or manipulated.

**Deployers** of such systems must also disclose the artificial origin of
the content.

**What's required**:
- Machine-readable marking/labelling of AI-generated content where technically
  feasible
- Detection mechanisms for AI-generated content
- Content provenance labelling

**Exceptions**: AI-generated content that is part of an obviously artistic,
creative, satirical, or fictional work, provided that the rights of third
parties are not affected.

### 50(4) — AI-Generated Text on Public Interest Matters

Deployers of AI systems that generate or manipulate text published for the
purpose of informing the public on matters of public interest must disclose
that the content has been artificially generated or manipulated.

This does not apply where the content has undergone human review and
editorial control and a natural person or legal entity holds editorial
responsibility.

## Article 52 — General-Purpose AI Transparency

Providers of general-purpose AI (GPAI) models must provide documentation
and information to downstream providers of AI systems that integrate the
GPAI model, to enable those downstream providers to comply with their own
transparency obligations.

## Practical Implementation

### For Chatbots / Conversational AI
- Display a clear notice: "You are interacting with an AI system"
- Place notice before or at the start of the conversation
- Ensure notice is accessible (multilingual where appropriate)

### For AI-Generated Content
- Apply machine-readable watermarks or metadata
- Provide visible labelling (e.g., "AI-generated")
- Maintain content provenance records

### For Emotion Recognition / Biometric Systems
- Provide advance notice to affected individuals
- Explain what data is being collected and for what purpose
- Obtain appropriate consent where required by GDPR

## Penalties

Non-compliance with transparency obligations under Article 50 can result in
administrative fines up to EUR 15 million or 3% of total worldwide annual
turnover, whichever is higher.

## Key Dates

- **2 August 2025**: Transparency obligations for GPAI models apply
- **2 August 2026**: Transparency obligations for other AI systems apply

## Citations

- Regulation (EU) 2024/1689, Articles 50-52
- Recitals 131-143
