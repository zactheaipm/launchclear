---
id: "us-texas-traiga"
law: "Texas Responsible AI Governance Act (TRAIGA), Texas Business &"
articles: []
effectiveDate: null
generatedBy: "claude-opus-4"
sources:
  - id: "tx-traiga"
verification:
  status: "unverified"
  lastAuditDate: null
  auditor: null
  issues: []
---
# Texas Responsible AI Governance Act (TRAIGA)

**Authority**: Texas Legislature; Texas Attorney General
**Legal Basis**: Texas Responsible AI Governance Act (TRAIGA), Texas Business &
Commerce Code Chapter 120
**Status**: Signed into law 2025; effective date 2026

## Overview

The Texas Responsible AI Governance Act (TRAIGA) establishes governance
requirements for deployers of high-risk artificial intelligence systems in
Texas. The Act focuses on preventing algorithmic discrimination and ensuring
transparency and accountability when AI systems are used to make consequential
decisions that materially affect consumers. It follows a deployer-focused
model, imposing primary obligations on entities that deploy (rather than
develop) high-risk AI systems.

## High-Risk AI System Definition

An AI system is classified as **high-risk** under TRAIGA when it is used as a
substantial factor in making a **consequential decision**. A consequential
decision is one that has a material legal or similarly significant effect on
a consumer's access to or the cost, terms, or availability of:

- **Employment**: Hiring, termination, promotion, compensation, work
  assignment, performance evaluation
- **Education**: Enrollment, financial aid, accreditation, certification,
  educational opportunity
- **Financial Services**: Lending, credit, insurance, banking services
- **Housing**: Rental, purchase, lease terms, property valuation
- **Healthcare**: Clinical decisions, coverage, cost of services, treatment
  access
- **Government Services**: Eligibility for benefits, permits, licenses,
  access to government programs
- **Legal Services**: Decisions that affect legal rights, obligations, or
  access to justice

## Deployer Governance Program

Deployers of high-risk AI systems must implement and maintain an **AI
governance program** that is reasonable for the deployer's size, complexity,
the nature of the AI system, and the risk of harm. The governance program
must include:

### Policies and Procedures

- Written policies for the development, procurement, deployment, and
  oversight of high-risk AI systems
- Designated personnel responsible for AI governance oversight
- Employee training on AI governance policies and procedures
- Procedures for receiving and responding to consumer complaints related
  to high-risk AI decisions

### Risk Identification and Mitigation

- Identification and documentation of known or reasonably foreseeable risks
  of algorithmic discrimination
- Reasonable measures to mitigate identified risks before and during deployment
- Ongoing monitoring of the AI system's performance and outputs for evidence
  of algorithmic discrimination or other harms

## Impact Assessments

### When Required

Deployers must complete an **impact assessment** for each high-risk AI system:
- Before initial deployment
- Annually thereafter
- Upon any material modification to the AI system or its use

### Assessment Contents

Each impact assessment must include:
- A description of the purpose, intended use, and deployment context of the
  AI system
- An analysis of potential risks of algorithmic discrimination, including
  risks to protected classes
- The categories of data processed as inputs and the outputs produced
- An evaluation of the system's performance, including metrics related to
  accuracy and fairness
- A description of transparency measures provided to affected consumers
- A description of human oversight mechanisms
- Post-deployment monitoring plans

Impact assessments must be retained for at least three years and made available
to the Attorney General upon request.

## Consumer Notice and Transparency

### Pre-Decision Notice

Deployers must provide consumers with notice that a high-risk AI system is
being used to make or substantially contribute to a consequential decision
about the consumer. The notice must:
- Be provided before or at the time of the decision
- Be clear, conspicuous, and in plain language
- Describe the role of the AI system in the decision

### Post-Decision Rights

When a consumer is subject to an adverse consequential decision, the
deployer must:
- Inform the consumer of the adverse decision
- Provide a statement that a high-risk AI system was used as a substantial
  factor in the decision
- Provide the consumer with an opportunity to **appeal** the decision,
  including meaningful human review
- Provide information about how to contact the deployer with questions

## Algorithmic Discrimination

### Definition

Algorithmic discrimination means any condition in which the use of a
high-risk AI system contributes to unlawful differential treatment or
disparate impact that disfavors a person or group based on actual or
perceived membership in a protected class, including:
- Race, color, ethnicity, or national origin
- Sex, gender, or sexual orientation
- Religion
- Age
- Disability
- Veteran or military status

## Enforcement

### Attorney General Enforcement

- The Texas Attorney General has **exclusive enforcement authority** under
  TRAIGA
- No private right of action
- The Attorney General must provide **90-day written notice** before bringing
  an enforcement action, allowing the deployer to cure the violation
- Violations are enforceable under the Texas Deceptive Trade Practices Act

### Affirmative Defense

A deployer has an affirmative defense if the deployer:
- Discovered and cured the violation within the 90-day cure period
- Was in material compliance with the governance program and impact
  assessment requirements
- Complied with a nationally or internationally recognized risk management
  framework (e.g., NIST AI RMF)

## Interaction with Other Laws

- TRAIGA does not limit obligations under federal anti-discrimination law
  (Title VII, ADA, ADEA, ECOA, Fair Housing Act)
- TRAIGA does not preempt existing Texas consumer protection law
- Employers using AI in hiring must also consider EEOC guidance on AI and
  employment decisions
- Multi-state deployers must separately comply with Colorado AI Act, NYC
  LL144, and other state-level AI requirements

## Citations

- Texas Responsible AI Governance Act (TRAIGA), TX Bus. & Com. Code Ch. 120
- Texas Deceptive Trade Practices Act, TX Bus. & Com. Code ยง 17.41 et seq.
- NIST AI Risk Management Framework (referenced as voluntary compliance
  framework for affirmative defense)
- EEOC Technical Assistance on AI and Employment (May 2022)
