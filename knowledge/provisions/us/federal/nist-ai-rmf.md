---
id: "us-federal-nist-ai-rmf"
law: "nist-ai-rmf"
articles: []
effectiveDate: null
generatedBy: "claude-opus-4"
sources:
  - id: "nist-ai-rmf"
verification:
  status: "unverified"
  lastAuditDate: null
  auditor: null
  issues: []
---
# US Federal â€” NIST AI Risk Management Framework

**Authority**: National Institute of Standards and Technology (NIST)
**Document**: NIST AI 100-1 (AI Risk Management Framework 1.0)
**Published**: January 2023
**Status**: Voluntary framework

## Overview

The NIST AI RMF provides a voluntary framework for managing risks associated
with AI systems throughout their lifecycle. While not legally binding, it is
increasingly referenced by federal agencies, included in procurement
requirements, and cited as a standard of care for AI governance.

## Framework Structure

The AI RMF is organised around four core functions:

### 1. GOVERN

Cultivate and implement a culture of risk management within organisations
designing, developing, deploying, or using AI systems.

Key activities:
- Establish AI risk management policies and procedures
- Define roles and responsibilities for AI governance
- Ensure diversity and inclusion in AI development teams
- Maintain transparency about AI system capabilities and limitations
- Document AI risk management processes

### 2. MAP

Establish context to frame risks for the AI system.

Key activities:
- Identify intended purpose and context of use
- Map potential AI risks and impacts
- Document assumptions and limitations
- Assess the AI system's interaction with its broader context
- Identify relevant stakeholders

### 3. MEASURE

Employ quantitative, qualitative, or mixed-method tools, techniques, and
methodologies to analyse, assess, benchmark, and monitor AI risk and
related impacts.

Key activities:
- Measure AI system performance and behaviour
- Evaluate for bias and fairness across demographics
- Test for robustness and reliability
- Assess security and privacy risks
- Track metrics over time

### 4. MANAGE

Allocate resources and develop response strategies to manage AI risks.

Key activities:
- Prioritise and respond to identified risks
- Implement risk mitigation measures
- Plan for incidents and failures
- Monitor and reassess risk management effectiveness
- Communicate risk management activities to stakeholders

## AI RMF Characteristics of Trustworthy AI

The framework identifies seven characteristics:
1. **Valid and Reliable**: Performs as intended, confirmed via testing
2. **Safe**: Does not cause unreasonable risk of harm
3. **Secure and Resilient**: Resistant to adversarial attacks
4. **Accountable and Transparent**: Processes are documented and explained
5. **Explainable and Interpretable**: Outputs can be understood
6. **Privacy-Enhanced**: Privacy protections built in
7. **Fair with Harmful Bias Managed**: Bias identified and mitigated

## Regulatory Significance

While voluntary, the NIST AI RMF is:
- Referenced in Executive Order 14110 (Safe, Secure, and Trustworthy AI)
- Incorporated into federal procurement guidance
- Cited by FTC as a reference for AI governance practices
- Used by state regulators as a compliance benchmark
- Adopted by industry as a governance framework

## Citations

- NIST AI 100-1: Artificial Intelligence Risk Management Framework (AI RMF 1.0)
- NIST AI RMF Playbook (companion resource)
- Executive Order 14110 on Safe, Secure, and Trustworthy AI
