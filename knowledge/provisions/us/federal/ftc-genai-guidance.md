# US Federal — FTC Guidance on AI-Generated Content

**Authority**: Federal Trade Commission
**Legal Basis**: FTC Act Section 5 (15 U.S.C. § 45)
**Status**: Active enforcement and rulemaking

## Overview

The FTC has issued guidance and taken enforcement actions specifically
addressing generative AI risks. The Commission's focus areas include
AI-generated deceptive content, synthetic media (deepfakes), voice cloning,
fake reviews, and undisclosed AI-generated content.

## Key FTC Positions on GenAI

### 1. Deceptive AI-Generated Content

The FTC considers it potentially deceptive under Section 5 to:

- Use AI to generate content that misleads consumers about its origin
- Deploy chatbots that fail to disclose they are AI when consumers would
  reasonably expect human interaction
- Create AI-generated testimonials or reviews that appear to be from real
  consumers
- Use AI to generate fake news articles or expert opinions

### 2. Deepfakes and Synthetic Media

The FTC has warned that:
- Using AI to create realistic fake images, videos, or audio of real
  people may violate Section 5
- Companies providing deepfake tools may be liable for foreseeable misuse
- Political deepfakes raise particular FTC concerns
- The FTC has proposed rules specifically targeting AI impersonation of
  individuals (voice cloning, likeness)

### 3. Synthetic Voice and Cloning

- AI voice cloning used for fraud or impersonation is a Section 5 violation
- Companies offering voice synthesis must implement safeguards against misuse
- The FTC Voice Cloning Challenge (2024) highlighted the need for detection
  tools

### 4. AI-Generated Reviews and Endorsements

- The FTC's updated Endorsement Guides (2023) address AI-generated reviews
- Fake AI-generated reviews are prohibited
- Companies must disclose material connections including AI involvement in
  generating or selecting testimonials

## Disclosure Requirements

While there is no comprehensive federal AI disclosure law, the FTC expects:

1. **Clear and conspicuous disclosure** when content is AI-generated and
   consumers might be misled about its origin
2. **Disclosure of AI involvement** in decisions that consumers expect to be
   human-made
3. **Truthful representation** of AI capabilities in marketing
4. **Disclosure of material limitations** of AI systems

## Enforcement Actions

The FTC has taken or announced enforcement actions related to:
- Companies using AI to generate fake reviews
- Deceptive marketing of AI capabilities
- AI tools that facilitated impersonation
- Data practices supporting AI training without adequate disclosure

## FTC Proposed Rules

The FTC has proposed or finalised rules addressing:
- **AI Impersonation Rule**: Prohibiting AI-generated content that
  impersonates individuals, government entities, or businesses
- **Updates to Telemarketing Sales Rule**: Addressing AI-generated voice
  calls and robocalls
- **Commercial Surveillance Rule**: Addressing AI-powered data collection
  and algorithmic decision-making

## Citations

- FTC Act Section 5 (15 U.S.C. § 45)
- FTC Blog: "Chatbots, deepfakes, and voice clones: AI deception for sale"
- FTC Endorsement Guides (16 CFR Part 255, updated 2023)
- FTC Supplemental Notice of Proposed Rulemaking: Trade Regulation Rule on
  Impersonation of Government and Businesses (Feb 2024)
- FTC Policy Statement on Biometric Information (2023)
