---
id: genai-content-policy
name: AI-Generated Content Labeling and Watermarking Policy
jurisdiction: multi
legalBasis: "EU AI Act Article 50, China CAC GenAI Measures, California SB 942"
requiredSections:
  - policy-overview
  - labeling-requirements
  - watermarking-implementation
  - jurisdiction-requirements
  - monitoring
---

# AI-Generated Content Labeling and Watermarking Policy

**Organisation**: {{organisation_name}}
**Effective date**: {{effective_date}}
**Last updated**: {{last_updated}}
**Applicable AI systems**: {{applicable_systems}}
**Target markets**: {{target_markets}}
**Status**: DRAFT — Requires legal review

---

## 1. Policy Overview

### 1.1 Purpose

{{policy_purpose}}

### 1.2 Scope

{{policy_scope}}

### 1.3 Content Types Covered

| Content Type | Generated by System? | Labeling Required? | Watermarking Required? |
|-------------|---------------------|-------------------|----------------------|
| Text | {{text_generated}} | {{text_labeling}} | {{text_watermarking}} |
| Images | {{image_generated}} | {{image_labeling}} | {{image_watermarking}} |
| Audio | {{audio_generated}} | {{audio_labeling}} | {{audio_watermarking}} |
| Video | {{video_generated}} | {{video_labeling}} | {{video_watermarking}} |
| Code | {{code_generated}} | {{code_labeling}} | {{code_watermarking}} |

---

## 2. Content Labeling Requirements

### 2.1 User-Facing Disclosure

{{user_facing_disclosure}}

### 2.2 Labeling Standards

{{labeling_standards}}

### 2.3 Disclosure Placement and Format

{{disclosure_placement}}

### 2.4 Deepfake / Synthetic Media Disclosure

<!-- Applicable when the system can generate realistic depictions of real persons or events. -->

{{deepfake_disclosure}}

---

## 3. Technical Watermarking Implementation

### 3.1 Watermarking Strategy

{{watermarking_strategy}}

### 3.2 Machine-Readable Marking

{{machine_readable_marking}}

### 3.3 C2PA / Content Credentials

{{c2pa_implementation}}

### 3.4 Metadata Standards

{{metadata_standards}}

### 3.5 Robustness Requirements

{{watermark_robustness}}

---

## 4. Jurisdiction-Specific Requirements

### {{#if_jurisdiction eu-ai-act}}

### 4.1 European Union — EU AI Act

**Applicable provisions**: Articles 50(1), 50(2), 50(4)

#### AI Interaction Disclosure (Article 50(1))

{{eu_interaction_disclosure}}

#### AI-Generated Content Marking (Article 50(2))

<!-- Providers of AI systems that generate synthetic audio, image, video or text content shall ensure that the outputs of the AI system are marked in a machine-readable format and detectable as artificially generated or manipulated. The technical solutions shall be effective, interoperable, robust and reliable. -->

{{eu_content_marking}}

#### Deepfake Disclosure (Article 50(4))

<!-- Deployers of an AI system that generates or manipulates image, audio or video content constituting a deep fake, shall disclose that the content has been artificially generated or manipulated. -->

{{eu_deepfake_disclosure}}

### {{/if_jurisdiction}}

### {{#if_jurisdiction china}}

### 4.2 China — CAC GenAI Measures and Deep Synthesis Regulations

**Applicable provisions**: Interim Measures for the Management of Generative AI Services (Articles 7, 9, 12), Deep Synthesis Provisions (Articles 6, 16, 17)

#### Mandatory Output Labeling (Article 12)

<!-- GenAI service providers shall mark generated content including images, videos, and text in accordance with relevant national standards. Content must be identifiable as AI-generated. -->

{{china_output_labeling}}

#### Content Review Obligations (Article 9)

{{china_content_review}}

#### Deep Synthesis Labeling (Article 16-17)

<!-- Providers of deep synthesis services shall add identifiable marks to content that may cause public confusion or misidentification. Must use techniques such as adding watermarks to generated or edited content. -->

{{china_deep_synthesis_labeling}}

### {{/if_jurisdiction}}

### {{#if_jurisdiction us-ca}}

### 4.3 California — SB 942 (GenAI Transparency Act)

**Applicable provisions**: California SB 942

#### AI-Generated Content Disclosure

<!-- SB 942 requires providers of generative AI systems to make available AI detection tools and to include manifest or latent disclosures in AI-generated content. -->

{{california_disclosure}}

#### Detection Tool Availability

{{california_detection_tools}}

#### Provenance Data

{{california_provenance}}

### {{/if_jurisdiction}}

### {{#if_jurisdiction uk}}

### 4.4 United Kingdom

**Applicable provisions**: ICO AI Guidance, DSIT Foundation Model Principles

{{uk_content_labeling}}

### {{/if_jurisdiction}}

### {{#if_jurisdiction singapore}}

### 4.5 Singapore

**Applicable provisions**: IMDA GenAI Governance Framework

{{singapore_content_labeling}}

### {{/if_jurisdiction}}

---

## 5. Operational Procedures

### 5.1 Content Classification

{{content_classification_process}}

### 5.2 Labeling Workflow

{{labeling_workflow}}

### 5.3 Exception Handling

{{exception_handling}}

### 5.4 Third-Party Content

{{third_party_content}}

---

## 6. Monitoring and Compliance

### 6.1 Monitoring Mechanisms

{{monitoring_mechanisms}}

### 6.2 Audit Process

{{audit_process}}

### 6.3 Incident Response

{{incident_response}}

### 6.4 Record-Keeping

{{record_keeping}}

---

## 7. Review and Updates

### 7.1 Review Schedule

{{review_schedule}}

### 7.2 Regulatory Monitoring

{{regulatory_monitoring}}

---

**REVIEW NOTES FOR LEGAL TEAM**:

{{review_notes}}

---

*This policy was generated by LaunchClear. AI-generated content labeling and watermarking requirements vary significantly across jurisdictions and are evolving rapidly. All content should be reviewed by qualified legal counsel for each target market. Technical watermarking implementations should be verified by the engineering team for effectiveness and robustness.*
