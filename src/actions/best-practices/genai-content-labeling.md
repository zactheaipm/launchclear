# AI-Generated Content Labeling and Watermarking

## Overview

Multiple jurisdictions now require AI-generated content to be labeled,
watermarked, or otherwise disclosed as machine-generated. Requirements vary
significantly by jurisdiction, content modality, and use case. This guide
covers implementation approaches for cross-jurisdictional compliance.

## Jurisdictional Requirements

### EU AI Act (Article 50)

- Deployers must disclose that content is artificially generated or
  manipulated where it constitutes a deep fake
- AI systems generating text published to inform the public on matters of
  public interest must be labeled as AI-generated
- Machine-readable format required for content detection
- Exemptions for artistic, satirical, or clearly fictional content

### China (CAC GenAI Measures, Deep Synthesis Regulations)

- **Mandatory labeling**: All AI-generated content must be labeled
- Machine-readable watermarks or metadata required
- Visible labels required on user-facing content
- Deep synthesis (deepfake) content requires conspicuous labels
- Service providers must maintain generation logs
- Labels must persist through distribution and sharing

### US Federal (FTC Guidance)

- No blanket federal mandate yet, but FTC considers failure to disclose AI
  involvement as potentially deceptive under Section 5
- Disclosure expected when consumers would reasonably expect human creation
- Synthetic media of real persons requires disclosure

### California (SB 942)

- GenAI providers must offer AI detection tools
- Requires content provenance mechanisms for AI-generated content
- Applies to providers with significant California user base

### UK

- Voluntary framework, but ICO expects transparency about AI processing
- AISI evaluating frontier model content labeling capabilities
- Content labeling increasingly expected as industry norm

### Singapore (IMDA GenAI Guidelines)

- Content provenance disclosure recommended
- Testing and evaluation should cover content labeling effectiveness

## Implementation Approaches

### 1. Machine-Readable Metadata (Recommended Baseline)

Embed metadata in generated content indicating AI origin:

- **C2PA (Coalition for Content Provenance and Authenticity)**:
  Open standard for content credentials. Embeds cryptographically
  signed metadata about content origin, editing history, and
  generation method. Supported by Adobe, Microsoft, Google, and others.
  Best for images, video, and documents.

- **IPTC metadata**: For images, embed IPTC fields indicating
  AI generation. Widely supported by media platforms.

- **HTTP headers**: For API-served content, include
  `AI-Generated: true` or similar headers.

- **Structured data markup**: For web content, use schema.org
  markup indicating AI authorship.

### 2. Visible Labels

Human-readable indicators of AI generation:

- **Text content**: Prepend or append disclosure (e.g., "This content
  was generated by AI" or "[AI-generated]")
- **Images**: Visible watermark, badge, or overlay indicating AI
  generation. Consider accessibility (screen readers).
- **Audio**: Audio preamble or periodic disclosure within generated
  speech
- **Video**: Persistent on-screen indicator or watermark frame

### 3. Invisible Watermarking

Embed imperceptible signals in generated content:

- **Text watermarking**: Statistical patterns in token selection
  that are detectable by analysis tools but invisible to readers
- **Image watermarking**: Frequency-domain watermarks embedded in
  pixel data, robust against compression and resizing
- **Audio watermarking**: Spectral watermarks in audio signal

### 4. Content Provenance Chain

Track the full lifecycle of generated content:

- Record which model generated the content
- Record the prompt or input that produced it
- Record timestamp and user identity (where appropriate)
- Maintain audit trail through editing and distribution

## Cross-Jurisdictional Strategy

For products operating across multiple markets:

1. **Implement C2PA as the baseline** — it satisfies machine-readable
   requirements across jurisdictions and is becoming an industry standard
2. **Add visible labels for China market** — China has the most
   prescriptive visible labeling requirements
3. **Implement content logging** — China requires generation logs;
   this also satisfies EU audit trail expectations
4. **Provide user-facing disclosure** — satisfies FTC transparency
   expectations and EU Article 50 requirements
5. **Test labeling persistence** — verify that labels survive content
   sharing, copying, screenshot, and format conversion

## Technical Considerations

- **Performance**: Watermarking and metadata embedding should not
  significantly increase latency
- **Robustness**: Watermarks should survive reasonable transformations
  (compression, resizing, format conversion, screenshots)
- **Compatibility**: Metadata formats should be readable by common
  tools and platforms
- **Privacy**: Content provenance should not inadvertently expose
  user identity or prompt content beyond what is required

## Common Pitfalls

- **Easily removable labels**: Labels that can be stripped with basic
  editing tools provide limited compliance value
- **Label fatigue**: Excessive or intrusive labels harm user experience;
  balance disclosure with usability
- **Inconsistent labeling**: Applying labels to some outputs but not
  others creates compliance gaps
- **Metadata stripping by platforms**: Some social media platforms strip
  metadata on upload — consider multiple labeling methods
- **Over-labeling**: Labeling content that is not AI-generated damages
  trust in the labeling system
